# PySpark example to clean the data and remove outliers
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, weekofyear, avg

spark = SparkSession.builder.appName("RetailSalesAnalysis").getOrCreate()

# Load data
file_path = "../data/sales_cleaned.csv"
df = spark.read.csv(file_path, header=True, inferSchema=True)

# Remove outliers and fill missing values
median_sales = df.approxQuantile("sales", [0.5], 0.0)[0]
df_cleaned = df.na.fill({"sales": median_sales})

# Aggregate data by week
df_weekly = df_cleaned.groupBy("category", weekofyear("date")).agg(avg("sales").alias("weekly_sales"))

# Show final dataset
df_weekly.show()

# Save processed data
df_weekly.write.csv("../data/processed_sales_data.csv", header=True)
